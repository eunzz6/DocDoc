{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\User\\newdoc_data_add.CSV', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>요즘 계속해서 피로하고 기운이 없어서 걱정이에요.</td>\n",
       "      <td>피로감</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>최근에 식욕이 많이 없어져서 걱정이에요.</td>\n",
       "      <td>식욕감퇴</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>소화가 잘 안되는 것 같기도 하고</td>\n",
       "      <td>소화불량</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>가끔 배도 아파요</td>\n",
       "      <td>복통</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>가끔 복부 통증도 있어요.</td>\n",
       "      <td>복통</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>몸살 같이 아파요</td>\n",
       "      <td>몸살</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>몸살 같이 몸이 지치고 힘들어요</td>\n",
       "      <td>몸살</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>몸살 기운 때문에 힘들어요</td>\n",
       "      <td>몸살</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>몸살 났어요</td>\n",
       "      <td>몸살</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>몸살 같아요</td>\n",
       "      <td>몸살</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1656 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     conversation label\n",
       "0     요즘 계속해서 피로하고 기운이 없어서 걱정이에요.   피로감\n",
       "1          최근에 식욕이 많이 없어져서 걱정이에요.  식욕감퇴\n",
       "2              소화가 잘 안되는 것 같기도 하고  소화불량\n",
       "3                       가끔 배도 아파요    복통\n",
       "4                  가끔 복부 통증도 있어요.    복통\n",
       "...                           ...   ...\n",
       "1651                    몸살 같이 아파요    몸살\n",
       "1652            몸살 같이 몸이 지치고 힘들어요    몸살\n",
       "1653               몸살 기운 때문에 힘들어요    몸살\n",
       "1654                       몸살 났어요    몸살\n",
       "1655                       몸살 같아요    몸살\n",
       "\n",
       "[1656 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리\n",
    "\n",
    "# 대화와 레이블 추출\n",
    "conversations = data['conversation'].tolist()\n",
    "labels = data['label'].tolist()\n",
    "\n",
    "# 토큰화\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(conversations)\n",
    "sequences = tokenizer.texts_to_sequences(conversations)\n",
    "\n",
    "# 시퀀스 패딩\n",
    "max_len = max([len(seq) for seq in sequences])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# 레이블 이진 벡터 변환\n",
    "label_binarizer = LabelBinarizer()\n",
    "encoded_labels = label_binarizer.fit_transform(labels)\n",
    "num_classes = len(label_binarizer.classes_)\n",
    "\n",
    "# 데이터 분할\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(\n",
    "    padded_sequences, encoded_labels, test_size=0.2, random_state=42 ,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "83/83 [==============================] - 6s 33ms/step - loss: 3.2044 - accuracy: 0.0763 - val_loss: 3.1258 - val_accuracy: 0.1175\n",
      "Epoch 2/1000\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 2.8302 - accuracy: 0.2613 - val_loss: 2.3403 - val_accuracy: 0.3946\n",
      "Epoch 3/1000\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 1.6341 - accuracy: 0.6405 - val_loss: 1.3441 - val_accuracy: 0.7199\n",
      "Epoch 4/1000\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.7894 - accuracy: 0.8784 - val_loss: 0.9127 - val_accuracy: 0.7982\n",
      "Epoch 5/1000\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.4128 - accuracy: 0.9517 - val_loss: 0.6638 - val_accuracy: 0.8253\n",
      "Epoch 6/1000\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.2303 - accuracy: 0.9796 - val_loss: 0.5709 - val_accuracy: 0.8645\n",
      "Epoch 7/1000\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.1435 - accuracy: 0.9909 - val_loss: 0.5037 - val_accuracy: 0.8795\n",
      "Epoch 8/1000\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.1008 - accuracy: 0.9947 - val_loss: 0.4725 - val_accuracy: 0.8825\n",
      "Epoch 9/1000\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 0.0713 - accuracy: 0.9970 - val_loss: 0.4338 - val_accuracy: 0.8765\n",
      "Epoch 10/1000\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0531 - accuracy: 0.9962 - val_loss: 0.4456 - val_accuracy: 0.8886\n",
      "Epoch 11/1000\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.0423 - accuracy: 0.9962 - val_loss: 0.4218 - val_accuracy: 0.8855\n",
      "Epoch 12/1000\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0356 - accuracy: 0.9962 - val_loss: 0.4114 - val_accuracy: 0.8825\n",
      "Epoch 13/1000\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.0283 - accuracy: 0.9977 - val_loss: 0.4028 - val_accuracy: 0.8976\n",
      "Epoch 14/1000\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.4053 - val_accuracy: 0.8976\n",
      "Epoch 15/1000\n",
      "83/83 [==============================] - 1s 16ms/step - loss: 0.0229 - accuracy: 0.9962 - val_loss: 0.4046 - val_accuracy: 0.8976\n",
      "Epoch 16/1000\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.0190 - accuracy: 0.9970 - val_loss: 0.4052 - val_accuracy: 0.8855\n",
      "Epoch 17/1000\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.0183 - accuracy: 0.9955 - val_loss: 0.4133 - val_accuracy: 0.8946\n",
      "Epoch 18/1000\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0161 - accuracy: 0.9970 - val_loss: 0.3933 - val_accuracy: 0.8886\n",
      "Epoch 19/1000\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0157 - accuracy: 0.9970 - val_loss: 0.4023 - val_accuracy: 0.8886\n",
      "Epoch 20/1000\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.4045 - val_accuracy: 0.8946\n",
      "Epoch 21/1000\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.4078 - val_accuracy: 0.9006\n",
      "Epoch 22/1000\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.4019 - val_accuracy: 0.8916\n",
      "Epoch 23/1000\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.4004 - val_accuracy: 0.8976\n",
      "Epoch 24/1000\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.3959 - val_accuracy: 0.8916\n",
      "Epoch 25/1000\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.3914 - val_accuracy: 0.8916\n",
      "Epoch 26/1000\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.4008 - val_accuracy: 0.8886\n",
      "Epoch 27/1000\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.0099 - accuracy: 0.9955 - val_loss: 0.3973 - val_accuracy: 0.8886\n",
      "Epoch 28/1000\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.4158 - val_accuracy: 0.8916\n",
      "Epoch 29/1000\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0086 - accuracy: 0.9962 - val_loss: 0.4177 - val_accuracy: 0.8916\n",
      "Epoch 30/1000\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.4219 - val_accuracy: 0.8946\n",
      "Epoch 31/1000\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.4062 - val_accuracy: 0.8916\n",
      "Epoch 32/1000\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.4251 - val_accuracy: 0.8886\n",
      "Epoch 33/1000\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.4200 - val_accuracy: 0.8916\n",
      "Epoch 34/1000\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.0072 - accuracy: 0.9962 - val_loss: 0.4275 - val_accuracy: 0.8976\n",
      "Epoch 35/1000\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.4196 - val_accuracy: 0.8946\n"
     ]
    }
   ],
   "source": [
    "# 모델 \n",
    "\n",
    "import joblib\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.callbacks import EarlyStopping \n",
    "# 모델 구성\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_len))\n",
    "model.add(LSTM(units=64))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# EarlyStopping 콜백 정의\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_sequences, train_labels, epochs=1000, batch_size=16, validation_data=(test_sequences, test_labels), callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# 학습된 모델 저장\n",
    "model.save('doc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8946\n",
      "Test Loss: 0.4196326434612274\n",
      "Test Accuracy: 0.8945783376693726\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_sequences, test_labels)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load(r'C:\\Users\\User\\BE\\34\\web\\model\\doc_model.pkl')\n",
    "max_len=14\n",
    "tokenizer=joblib.load(r\"C:\\Users\\User\\BE\\34\\web\\model\\tokenizer.joblib\")\n",
    "label_binarizer = joblib.load(r\"C:\\Users\\User\\BE\\34\\web\\model\\labelbinarizer.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: gensim in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (4.3.1)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (1.9.2)\n",
      "Requirement already satisfied: python-mecab-ko in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (1.3.3)\n",
      "Requirement already satisfied: wget in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (3.2)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from konlpy) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from konlpy) (1.23.5)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from konlpy) (4.9.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from wordcloud) (9.5.0)\n",
      "Requirement already satisfied: python-mecab-ko-dic in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from python-mecab-ko) (2.1.1.post2)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from JPype1>=0.7.0->konlpy) (22.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\envs\\ml_pipeline\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy pandas seaborn gensim wordcloud python-mecab-ko wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "['식욕감퇴' '소화불량' '체중감소' '두통']\n"
     ]
    }
   ],
   "source": [
    "from mecab import MeCab\n",
    "from konlpy.tag import Kkma\n",
    "# def tokenize_sentences(text):\n",
    "#     mecab = MeCab()\n",
    "#     tokens = mecab.nouns(text)\n",
    "#     return tokens\n",
    "def tokenize_sentences(text):\n",
    "    kkma = Kkma()\n",
    "    sentences = kkma.sentences(text)\n",
    "    return sentences\n",
    "\n",
    "# new_texts = ['갑자기 심장이 빨리 뛰어요.',\n",
    "#              '공복 혈압도 많이 낮은 것 같아요.',\n",
    "#              '빈혈 증상도 같이 오는 기분이에요  . 그리고 배가 너무 아파요',\n",
    "#              '소화가 너무 안 되는 느낌이 들어요.',\n",
    "#              '입맛이 없어서 아무것도 안 먹고 있어요.',\n",
    "#              '혹시 머리도 너무 아픈데 두통약도 처방해 주실 수 있나요.',\n",
    "#              '속이 울렁거리고 식욕이 없어요. 그래서 살이 3kg가 빠졌어요.',\n",
    "#              '가끔 어지러운데 심하진 않아요.',\n",
    "#              '아니요. 똑같아요.',\n",
    "#              '네 감사합니다.']\n",
    "\n",
    "new_texts = ['요즘에 배가 자주 아파서 식욕이 많이 줄었어요',\n",
    "             '식사 후에 위가 불편해요. 또 몸무게도 많이 줄었어요','네 감사합니다'\n",
    "             ]\n",
    "\n",
    "\n",
    "tokenized_sentences = []\n",
    "for text in new_texts:\n",
    "    sentences = tokenize_sentences(text)\n",
    "    tokenized_sentences.extend(sentences)\n",
    "\n",
    "new_sequences = tokenizer.texts_to_sequences(tokenized_sentences)\n",
    "new_padded_sequences = pad_sequences(new_sequences, maxlen=14)\n",
    "predictions = model.predict(new_padded_sequences)\n",
    "\n",
    "decoded_labels = label_binarizer.inverse_transform(predictions)\n",
    "print(decoded_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['심장',\n",
       " '공복',\n",
       " '혈압',\n",
       " '것',\n",
       " '빈혈',\n",
       " '증상',\n",
       " '기분',\n",
       " '배',\n",
       " '소화',\n",
       " '느낌',\n",
       " '입맛',\n",
       " '아무것',\n",
       " '머리',\n",
       " '두통약',\n",
       " '처방',\n",
       " '수',\n",
       " '속',\n",
       " '식욕',\n",
       " '살',\n",
       " '데',\n",
       " '감사']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['갑자기 심장이 빨리 뛰어요.',\n",
       " '공복 혈압도 많이 낮은 것 같아요.',\n",
       " '빈혈 증상도 같이 오는 기분이에요 .',\n",
       " '그리고 배가 너무 아파요',\n",
       " '소화가 너무 안 되는 느낌이 들어요.',\n",
       " '입맛이 없어서 아무것도 안 먹고 있어요.',\n",
       " '혹시 머리도 너무 아픈데 두통약도 처방해 주실 수 있나요.',\n",
       " '속이 울렁거리고 식욕이 없어요.',\n",
       " '그래서 살이 3kg 가 빠졌어요.',\n",
       " '가끔 어지러운데 심하진 않아요.',\n",
       " '아니요. 똑같아요.',\n",
       " '네 감사합니다.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 1:\n",
      "Label 1: 식욕감퇴, Probability: 0.560653567314148\n",
      "Label 2: 복통, Probability: 0.3758377134799957\n",
      "Label 3: 속쓰림, Probability: 0.018018782138824463\n",
      "Label 4: 식욕증가, Probability: 0.017916684970259666\n",
      "Label 5: 요통, Probability: 0.00590095529332757\n",
      "Label 6: 체중감소, Probability: 0.0039043889846652746\n",
      "Label 7: 발진, Probability: 0.0026953592896461487\n",
      "Label 8: 체중증가, Probability: 0.0023000496439635754\n",
      "Label 9: 발열, Probability: 0.002281367313116789\n",
      "Label 10: 변비, Probability: 0.0021990041714161634\n",
      "text 2:\n",
      "Label 1: 소화불량, Probability: 0.9668372869491577\n",
      "Label 2: 속쓰림, Probability: 0.013055309653282166\n",
      "Label 3: 요통, Probability: 0.005066601559519768\n",
      "Label 4: 식욕감퇴, Probability: 0.004898895975202322\n",
      "Label 5: 발진, Probability: 0.0030602861661463976\n",
      "Label 6: 변비, Probability: 0.00206229486502707\n",
      "Label 7: 호흡곤란, Probability: 0.0016051407437771559\n",
      "Label 8: 식욕증가, Probability: 0.0008026182185858488\n",
      "Label 9: 신경통, Probability: 0.0007015858427621424\n",
      "Label 10: 몸살, Probability: 0.0006313872872851789\n",
      "text 3:\n",
      "Label 1: 체중감소, Probability: 0.6181382536888123\n",
      "Label 2: 식욕감퇴, Probability: 0.29281213879585266\n",
      "Label 3: 속쓰림, Probability: 0.037003740668296814\n",
      "Label 4: 혈압감소, Probability: 0.01959974318742752\n",
      "Label 5: 구토, Probability: 0.0064725494012236595\n",
      "Label 6: 혈압증가, Probability: 0.005637503694742918\n",
      "Label 7: 발열, Probability: 0.003896463895216584\n",
      "Label 8: 몸살, Probability: 0.0035300166346132755\n",
      "Label 9: 체중증가, Probability: 0.002381176920607686\n",
      "Label 10: 두통, Probability: 0.002265959046781063\n",
      "text 4:\n",
      "Label 1: 두통, Probability: 0.13036487996578217\n",
      "Label 2: 빈혈, Probability: 0.12491418421268463\n",
      "Label 3: 피로감, Probability: 0.12177316844463348\n",
      "Label 4: 체중증가, Probability: 0.10570719093084335\n",
      "Label 5: 혈압증가, Probability: 0.09520560503005981\n",
      "Label 6: 어지럼증, Probability: 0.08130022138357162\n",
      "Label 7: 변비, Probability: 0.04331289604306221\n",
      "Label 8: 식욕증가, Probability: 0.033695612102746964\n",
      "Label 9: 호흡곤란, Probability: 0.030541829764842987\n",
      "Label 10: 구토, Probability: 0.028785713016986847\n",
      "Symptoms:\n",
      "['식욕감퇴', '복통', '소화불량', '체중감소']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_names = label_binarizer.classes_\n",
    "top_k = 10 \n",
    "\n",
    "top_k_indices = np.argsort(-predictions, axis=1)[:, :top_k]\n",
    "top_k_probabilities = np.take_along_axis(predictions, top_k_indices, axis=1)\n",
    "\n",
    "symptom = []  \n",
    "for i in range(predictions.shape[0]):\n",
    "    print(f\"text {i+1}:\")\n",
    "    for j in range(top_k):\n",
    "        label_index = top_k_indices[i, j]\n",
    "        label_name = label_names[label_index]\n",
    "        prob = top_k_probabilities[i, j]\n",
    "        print(f\"Label {j+1}: {label_name}, Probability: {prob}\")\n",
    "        \n",
    "        if prob > 0.3:\n",
    "            symptom.append(label_name)\n",
    "    \n",
    "    # print()\n",
    "\n",
    "print(\"Symptoms:\")\n",
    "print(symptom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "joblib.dump(label_binarizer, r'C:\\Users\\User\\MLOps\\model\\label_binarizer2.pkl')\n",
    "joblib.dump(tokenizer, r'C:\\Users\\User\\MLOps\\model\\tokenizer2.pkl')\n",
    "joblib.dump(model, 'doc_model.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
